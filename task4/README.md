### Logits 是神经网络和机器学习中常见的术语，特别是在分类任务中。

1. 定义：Logits 是指未经过归一化处理的原始输出（分数）。在一个神经网络的输出层，尤其是用于分类问题的神经网络中，网络会输出一组值。Logits 就是这些值，它们可能是正数、负数或零，并且没有具体的概率意义。

2. 使用场景：
    * 在多分类问题中，模型的输出可能是多个类别的得分，这些得分并没有被转换成概率值。通过 softmax 函数（或 sigmoid 函数用于二分类问题），这些 logits 被转化为概率分布，概率的和为 1，表示模型对每个类别的信心。
    * 举例来说，假设一个三分类问题，网络输出 [2.5, 1.0, -0.5] 这样的 logits。经过 softmax 后，转换成的概率可能是 [0.7, 0.2, 0.1]，表示模型认为第一个类别的概率最大。

3. 与概率的关系：

* Logits 并不是直接的概率值，而是模型在没有进行概率归一化时输出的分数。要将 logits 转化为概率，通常使用 softmax 函数来进行归一化。Softmax 函数公式如下：

$$
P(y_i) = \frac{e^{logit_i}}{\sum_{j=1}^n e^{logit_j}}
$$

* 其中 $P(y_i)$ 是类别 $i$ 的预测概率，$logit_i$ 是该类别的 logits 值。

4. 在损失函数中的作用：

* 在训练神经网络时，很多损失函数（比如交叉熵损失函数）期望输入的是 logits 而不是经过 softmax 处理后的概率。这是因为在损失函数中同时计算 logits 和 softmax 具有更好的数值稳定性。

